{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEcmu3pz+6aC/CUKzMAj1X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpastolfo/Seismic-Velocity-Model-Inversion/blob/main/modelos(versao-1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos UNet e UNet_mod e a função loss\n",
        "###### No treinamento, chamar **from modelos import get_unet, get_unet_mod, ssim_loss, ssim_loss_rsme**"
      ],
      "metadata": {
        "id": "NwHs2aN8jW-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### DEEP LEARNING IMPORTS\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D, UpSampling2D\n",
        "from tensorflow.keras.layers import concatenate, add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "jkDuPXFhjImP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, momentum=0.9, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization(momentum=momentum)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "amZb86tQjFgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1S69Ozsi54P"
      },
      "outputs": [],
      "source": [
        "# defenição das arquiteturas  \n",
        "def get_unet(input_img, output_filters=1, n_filters = 16, dropout = 0.2, moment=0.9, batchnorm = True):\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, momentum=moment, kernel_size = 6, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 6, momentum=moment, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 6, momentum=moment , batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 6, momentum=moment , batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "\n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 6, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    # Expansive Path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, momentum=moment ,batchnorm = batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    outputs = Conv2D(output_filters, (1, 1), activation='linear')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet_mod(input_img, output_filters=1, n_filters = 16, dropout = 0.2, moment=0.9, batchnorm = True):\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, momentum=moment, kernel_size = 6, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 6, momentum=moment, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 6, momentum=moment , batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 6, momentum=moment , batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "\n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 6, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    # Expansive Path\n",
        "    u6 = tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, momentum=moment ,batchnorm = batchnorm)\n",
        " \n",
        "\n",
        "    u7 = tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    u8 = tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "\n",
        "    u9 = tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(c8)\n",
        "\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, momentum=moment , batchnorm = batchnorm)\n",
        "\n",
        "    outputs = Conv2D(output_filters, (1, 1), activation='linear')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6n1qQKJJjEbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss functtion similaridade estrutural\n",
        "coef=0.5\n",
        "def ssim_loss(y_true, y_pred):\n",
        "      return 1-tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.5,filter_size=5))\n",
        "def ssim_loss_rsme(y_true, y_pred):\n",
        "    ssim2=1-tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.5,filter_size=3))\n",
        "    l2=K.sum(((y_true-y_pred)**2), axis=-1)\n",
        "    loss=(coef*ssim2)+(l2*(1-coef))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "b5VjWPN6jTXo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}